{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/d7/ecf66c1cd12dc28b4040b15ab4d17b773b87fa9d29ca16125de01adb36cd/numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2MB)\n",
      "\u001b[K     |████████████████████████████████| 18.2MB 19.2MB/s eta 0:00:01\n",
      "\u001b[31mERROR: mosaic-ai-serving 1.0.0 has requirement Flask==2.1.1; python_version >= \"3.7\", but you'll have flask 2.2.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-serving 1.0.0 has requirement numpy==1.24.1; python_version >= \"3.10\", but you'll have numpy 1.26.4 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-1.26.4\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/1b/12521efcbc6058e2673583bb096c2b5046a9df39bd73eca392c1efed24e5/pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0MB)\n",
      "\u001b[K     |████████████████████████████████| 13.0MB 16.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/3d/a121f284241f08268b21359bd425f7d4825cffc5ac5cd0e1b3d82ffd2b10/pytz-2024.1-py2.py3-none-any.whl (505kB)\n",
      "\u001b[K     |████████████████████████████████| 512kB 86.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tzdata>=2022.7\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/58/f9c9e6be752e9fcb8b6a0ee9fb87e6e7a1f6bcab2cdc73f02bb7ba91ada0/tzdata-2024.1-py2.py3-none-any.whl (345kB)\n",
      "\u001b[K     |████████████████████████████████| 348kB 79.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.22.4; python_version < \"3.11\"\n",
      "  Using cached https://files.pythonhosted.org/packages/4b/d7/ecf66c1cd12dc28b4040b15ab4d17b773b87fa9d29ca16125de01adb36cd/numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting python-dateutil>=2.8.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/57/56b9bcc3c9c6a792fcbaf139543cee77261f3651ca9da0c93f5c1221264b/python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229kB)\n",
      "\u001b[K     |████████████████████████████████| 235kB 86.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six>=1.5\n",
      "  Downloading https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl\n",
      "\u001b[31mERROR: openapi-schema-validator 0.6.2 has requirement jsonschema<5.0.0,>=4.19.1, but you'll have jsonschema 4.19.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-serving 1.0.0 has requirement Flask==2.1.1; python_version >= \"3.7\", but you'll have flask 2.2.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-serving 1.0.0 has requirement numpy==1.24.1; python_version >= \"3.10\", but you'll have numpy 1.26.4 which is incompatible.\u001b[0m\n",
      "Installing collected packages: pytz, tzdata, numpy, six, python-dateutil, pandas\n",
      "Successfully installed numpy-1.26.4 pandas-2.2.2 python-dateutil-2.9.0.post0 pytz-2024.1 six-1.16.0 tzdata-2024.1\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Product Dimension Table\n",
    "categories = ['Dairy', 'Beverages', 'Snacks', 'Cleaning', 'Personal Care', 'Bakery', 'Frozen', 'Produce', 'Meat', 'Cereals']\n",
    "subcategories = ['Organic', 'Gluten-Free', 'Low-Fat', 'Sugar-Free']\n",
    "product_df = pd.DataFrame({\n",
    "    'Product_ID': range(1, 101),\n",
    "    'Product_Name': ['Product_' + str(i) for i in range(1, 101)],\n",
    "    'Category': np.random.choice(categories, 100),\n",
    "    'Subcategory': np.random.choice(subcategories, 100),\n",
    "})\n",
    "\n",
    "# Seasonality Dimension Table\n",
    "date_range = pd.date_range(start='2020-01-01', end='2024-03-31')\n",
    "seasonality_df = pd.DataFrame({\n",
    "    'Date': date_range,\n",
    "    'Day_of_Week': date_range.day_name(),\n",
    "    'Month': date_range.month_name(),\n",
    "    'Season': np.where(date_range.month % 12 < 3, 'Winter', \n",
    "                       np.where(date_range.month < 6, 'Spring', \n",
    "                                np.where(date_range.month < 9, 'Summer', 'Fall'))),\n",
    "    'Holiday': np.random.choice([True, False], len(date_range), p=[0.1, 0.9]),\n",
    "})\n",
    "\n",
    "# Inventory Dimension Table\n",
    "inventory_items_per_product = 5  # Each product has 5 inventory items\n",
    "total_inventory_items = len(product_df) * inventory_items_per_product\n",
    "inventory_dim_df = pd.DataFrame({\n",
    "    'Inventory_ID': range(1, total_inventory_items + 1),\n",
    "    'Product_ID': np.repeat(product_df['Product_ID'].values, inventory_items_per_product),\n",
    "    'Restock_Frequency': np.random.choice(['Weekly', 'Bi-Weekly', 'Monthly'], total_inventory_items),\n",
    "    'Lead_Time_Days': np.random.randint(1, 15, total_inventory_items),  # Simulated lead time in days for restocking\n",
    "    #'Perishable': np.random.choice([True, False], total_inventory_items, p=[0.3, 0.7]),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Base prices for each product within the specified range\n",
    "base_prices = pd.Series(np.random.uniform(10, 1000, size=len(product_df)), index=product_df['Product_ID'])\n",
    "\n",
    "# Fact Table: Daily Pricing and Sales Data\n",
    "daily_data = pd.DataFrame({\n",
    "    'Date': np.repeat(seasonality_df['Date'].values, len(product_df)),\n",
    "    'Product_ID': np.tile(product_df['Product_ID'].values, len(seasonality_df)),\n",
    "})\n",
    "\n",
    "# Assigning consistent selling prices with minor daily fluctuations\n",
    "daily_data['Base_Selling_Price'] = daily_data['Product_ID'].map(base_prices)\n",
    "daily_variation = np.random.normal(1.0, 0.1, size=len(daily_data))  # Small percentage variation each day\n",
    "daily_data['Selling_Price'] = daily_data['Base_Selling_Price'] * daily_variation\n",
    "\n",
    "# Define a percentage range to reduce the selling price by, to set the cost price\n",
    "# For example, cost price will be 40% to 90% of the selling price\n",
    "cost_price_percentage_min = 0.4\n",
    "cost_price_percentage_max = 0.9\n",
    "# Generate a random percentage reduction within the defined range for each product\n",
    "# This ensures variability but consistency for each product's cost price relative to its selling price\n",
    "percentage_reduction = pd.Series(np.random.uniform(cost_price_percentage_min, cost_price_percentage_max, size=len(product_df)), index=product_df['Product_ID'])\n",
    "# Apply the percentage reduction to the selling price to calculate the cost price\n",
    "# The cost price for each product will now be consistently based on its selling price\n",
    "daily_data['Cost_Price'] = daily_data.apply(lambda row: row['Selling_Price'] * percentage_reduction[row['Product_ID']], axis=1)\n",
    "\n",
    "# Competitor prices close but varied around the selling price\n",
    "daily_data['Competitor_Price'] = daily_data['Selling_Price'] * np.random.uniform(0.9, 1.1, size=len(daily_data))\n",
    "\n",
    "# Function to adjust units sold based on conditions discussed\n",
    "def units_sold(row):\n",
    "    return np.random.randint(100, 5000)  # Ensuring within the range\n",
    "\n",
    "daily_data['Units_Sold'] = daily_data.apply(units_sold, axis=1)\n",
    "daily_data['Revenue'] = daily_data['Units_Sold'] * daily_data['Selling_Price']\n",
    "\n",
    "\n",
    "# Inventory Fact Table: Assuming inventory is adjusted based on sales\n",
    "inventory_fact_df = pd.DataFrame({\n",
    "    'Date': np.repeat(seasonality_df['Date'].values, total_inventory_items),\n",
    "    'Inventory_ID': np.tile(inventory_dim_df['Inventory_ID'].values, len(seasonality_df)),\n",
    "    'Product_ID': np.tile(inventory_dim_df['Product_ID'].values, len(seasonality_df))\n",
    "})\n",
    "\n",
    "# Assuming restocking to initial levels daily for simplicity\n",
    "inventory_fact_df['Restocked_Units'] = np.where(inventory_fact_df['Date'].dt.dayofweek == 0,\n",
    "                                                np.random.randint(100, 1000, size=len(inventory_fact_df)),\n",
    "                                                0)\n",
    "\n",
    "# Simulate daily sales deductions from inventory\n",
    "inventory_fact_df['Daily_Sales'] = np.random.randint(10, 100, size=len(inventory_fact_df))\n",
    "\n",
    "# Calculate net stock level change\n",
    "inventory_fact_df['Net_Stock_Change'] = inventory_fact_df['Restocked_Units'] - inventory_fact_df['Daily_Sales']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Base_Selling_Price</th>\n",
       "      <th>Selling_Price</th>\n",
       "      <th>Cost_Price</th>\n",
       "      <th>Competitor_Price</th>\n",
       "      <th>Units_Sold</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>620.895851</td>\n",
       "      <td>738.331338</td>\n",
       "      <td>523.867455</td>\n",
       "      <td>785.622870</td>\n",
       "      <td>3282</td>\n",
       "      <td>2.423203e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>122.700010</td>\n",
       "      <td>117.030091</td>\n",
       "      <td>54.213319</td>\n",
       "      <td>126.761434</td>\n",
       "      <td>3785</td>\n",
       "      <td>4.429589e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>351.770911</td>\n",
       "      <td>350.153820</td>\n",
       "      <td>149.091977</td>\n",
       "      <td>316.811768</td>\n",
       "      <td>4939</td>\n",
       "      <td>1.729410e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>512.337819</td>\n",
       "      <td>453.589849</td>\n",
       "      <td>391.816273</td>\n",
       "      <td>455.000834</td>\n",
       "      <td>429</td>\n",
       "      <td>1.945900e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>875.480299</td>\n",
       "      <td>875.961161</td>\n",
       "      <td>572.689826</td>\n",
       "      <td>817.710505</td>\n",
       "      <td>1131</td>\n",
       "      <td>9.907121e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155195</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>96</td>\n",
       "      <td>415.532606</td>\n",
       "      <td>441.877963</td>\n",
       "      <td>257.024851</td>\n",
       "      <td>431.136239</td>\n",
       "      <td>4510</td>\n",
       "      <td>1.992870e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155196</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>97</td>\n",
       "      <td>318.105320</td>\n",
       "      <td>334.200746</td>\n",
       "      <td>149.171105</td>\n",
       "      <td>307.404064</td>\n",
       "      <td>1073</td>\n",
       "      <td>3.585974e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155197</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>98</td>\n",
       "      <td>680.349433</td>\n",
       "      <td>672.499505</td>\n",
       "      <td>270.564806</td>\n",
       "      <td>714.116061</td>\n",
       "      <td>1771</td>\n",
       "      <td>1.190997e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155198</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>99</td>\n",
       "      <td>609.721457</td>\n",
       "      <td>670.126013</td>\n",
       "      <td>284.059349</td>\n",
       "      <td>697.136460</td>\n",
       "      <td>4672</td>\n",
       "      <td>3.130829e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155199</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>100</td>\n",
       "      <td>370.947791</td>\n",
       "      <td>352.033163</td>\n",
       "      <td>142.912108</td>\n",
       "      <td>373.728964</td>\n",
       "      <td>4790</td>\n",
       "      <td>1.686239e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date  Product_ID  Base_Selling_Price  Selling_Price  Cost_Price  \\\n",
       "0      2020-01-01           1          620.895851     738.331338  523.867455   \n",
       "1      2020-01-01           2          122.700010     117.030091   54.213319   \n",
       "2      2020-01-01           3          351.770911     350.153820  149.091977   \n",
       "3      2020-01-01           4          512.337819     453.589849  391.816273   \n",
       "4      2020-01-01           5          875.480299     875.961161  572.689826   \n",
       "...           ...         ...                 ...            ...         ...   \n",
       "155195 2024-03-31          96          415.532606     441.877963  257.024851   \n",
       "155196 2024-03-31          97          318.105320     334.200746  149.171105   \n",
       "155197 2024-03-31          98          680.349433     672.499505  270.564806   \n",
       "155198 2024-03-31          99          609.721457     670.126013  284.059349   \n",
       "155199 2024-03-31         100          370.947791     352.033163  142.912108   \n",
       "\n",
       "        Competitor_Price  Units_Sold       Revenue  \n",
       "0             785.622870        3282  2.423203e+06  \n",
       "1             126.761434        3785  4.429589e+05  \n",
       "2             316.811768        4939  1.729410e+06  \n",
       "3             455.000834         429  1.945900e+05  \n",
       "4             817.710505        1131  9.907121e+05  \n",
       "...                  ...         ...           ...  \n",
       "155195        431.136239        4510  1.992870e+06  \n",
       "155196        307.404064        1073  3.585974e+05  \n",
       "155197        714.116061        1771  1.190997e+06  \n",
       "155198        697.136460        4672  3.130829e+06  \n",
       "155199        373.728964        4790  1.686239e+06  \n",
       "\n",
       "[155200 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map day of week to weekend indicator\n",
    "weekend_mapping = {'Monday': 0, 'Tuesday': 0, 'Wednesday': 0, 'Thursday': 0, 'Friday': 0, 'Saturday': 1, 'Sunday': 1}\n",
    "seasonality_df['Is_Weekend'] = seasonality_df['Day_of_Week'].map(weekend_mapping)\n",
    "\n",
    "# Calculate total units sold for each product\n",
    "total_units_by_product = daily_data.groupby('Product_ID')['Units_Sold'].sum()\n",
    "# Identify the top 5 products\n",
    "top_5_products = total_units_by_product.nlargest(5).index.tolist()\n",
    "\n",
    "# Update to adjust selling price for holidays and demand fluctuations\n",
    "def adjust_selling_price(row):\n",
    "   holiday_factor = 1.1 if row['Is_Holiday'] else 1.0\n",
    "   weekend_factor = 1.05 if row['Is_Weekend'] else 1.0\n",
    "   demand_fluctuation = np.random.uniform(0.95, 1.05)\n",
    "   return row['Base_Selling_Price'] * holiday_factor * weekend_factor * demand_fluctuation\n",
    "# Update to adjust units sold based on various factors\n",
    "def adjust_units_sold(row):\n",
    "   price_sensitivity = -0.1  # Example sensitivity, adjust based on analysis\n",
    "   holiday_boost = 1.5 if row['Is_Holiday'] else 1.0\n",
    "   weekend_boost = 1.0\n",
    "   if row['Product_ID'] in top_5_products and row['Is_Weekend'] and np.random.rand() <0.8:\n",
    "        weekend_boost = 1.3\n",
    "   price_factor = 1.0 if row['Selling_Price'] <= row['Competitor_Price'] else 0.5\n",
    "   price_effect = np.exp(price_sensitivity * (row['Selling_Price'] - row['Competitor_Price']))\n",
    "   units_sold = row['Units_Sold'] * holiday_boost * weekend_boost * price_factor\n",
    "   return max(0, np.round(units_sold))  # Ensure units sold is not negative\n",
    "# Add columns to indicate holidays and weekends\n",
    "seasonality_df['Is_Holiday'] = seasonality_df['Holiday'].astype(int)\n",
    "\n",
    "# Map day of week to weekend indicator\n",
    "weekend_mapping = {'Monday': 0, 'Tuesday': 0, 'Wednesday': 0, 'Thursday': 0, 'Friday': 0, 'Saturday': 1, 'Sunday': 1}\n",
    "seasonality_df['Is_Weekend'] = seasonality_df['Day_of_Week'].map(weekend_mapping)\n",
    "\n",
    "# Merge seasonality info into daily_data\n",
    "daily_data = daily_data.merge(seasonality_df[['Date', 'Is_Holiday', 'Is_Weekend']], on='Date', how='left')\n",
    "# Apply adjustments\n",
    "daily_data['Selling_Price'] = daily_data.apply(adjust_selling_price, axis=1)\n",
    "daily_data['Units_Sold'] = daily_data.apply(adjust_units_sold, axis=1)\n",
    "daily_data['Revenue'] = daily_data['Units_Sold'] * daily_data['Selling_Price']\n",
    "daily_data['Competitor_Price'] = daily_data['Selling_Price'] * np.random.uniform(0.9, 1.1, size=len(daily_data))\n",
    "\n",
    "# Display a sample of the adjusted daily data\n",
    "print(daily_data.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inventory_items={key:5 for key in range(1,101)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Inventory_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Restocked_Units</th>\n",
       "      <th>Daily_Sales</th>\n",
       "      <th>Net_Stock_Change</th>\n",
       "      <th>Base_Selling_Price</th>\n",
       "      <th>Selling_Price</th>\n",
       "      <th>Cost_Price</th>\n",
       "      <th>Competitor_Price</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Is_Holiday</th>\n",
       "      <th>Is_Weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.638025e+11</td>\n",
       "      <td>-88</td>\n",
       "      <td>620.895851</td>\n",
       "      <td>591.075172</td>\n",
       "      <td>523.867455</td>\n",
       "      <td>593.330709</td>\n",
       "      <td>4.840979e+14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.638025e+11</td>\n",
       "      <td>-93</td>\n",
       "      <td>620.895851</td>\n",
       "      <td>591.075172</td>\n",
       "      <td>523.867455</td>\n",
       "      <td>593.330709</td>\n",
       "      <td>4.840979e+14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.638025e+11</td>\n",
       "      <td>-21</td>\n",
       "      <td>620.895851</td>\n",
       "      <td>591.075172</td>\n",
       "      <td>523.867455</td>\n",
       "      <td>593.330709</td>\n",
       "      <td>4.840979e+14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.638025e+11</td>\n",
       "      <td>-81</td>\n",
       "      <td>620.895851</td>\n",
       "      <td>591.075172</td>\n",
       "      <td>523.867455</td>\n",
       "      <td>593.330709</td>\n",
       "      <td>4.840979e+14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.638025e+11</td>\n",
       "      <td>-76</td>\n",
       "      <td>620.895851</td>\n",
       "      <td>591.075172</td>\n",
       "      <td>523.867455</td>\n",
       "      <td>593.330709</td>\n",
       "      <td>4.840979e+14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Inventory_ID  Product_ID  Restocked_Units   Daily_Sales  \\\n",
       "0 2020-01-01             1           1                0  1.638025e+11   \n",
       "1 2020-01-01             2           1                0  1.638025e+11   \n",
       "2 2020-01-01             3           1                0  1.638025e+11   \n",
       "3 2020-01-01             4           1                0  1.638025e+11   \n",
       "4 2020-01-01             5           1                0  1.638025e+11   \n",
       "\n",
       "   Net_Stock_Change  Base_Selling_Price  Selling_Price  Cost_Price  \\\n",
       "0               -88          620.895851     591.075172  523.867455   \n",
       "1               -93          620.895851     591.075172  523.867455   \n",
       "2               -21          620.895851     591.075172  523.867455   \n",
       "3               -81          620.895851     591.075172  523.867455   \n",
       "4               -76          620.895851     591.075172  523.867455   \n",
       "\n",
       "   Competitor_Price       Revenue  Is_Holiday  Is_Weekend  \n",
       "0        593.330709  4.840979e+14           0           0  \n",
       "1        593.330709  4.840979e+14           0           0  \n",
       "2        593.330709  4.840979e+14           0           0  \n",
       "3        593.330709  4.840979e+14           0           0  \n",
       "4        593.330709  4.840979e+14           0           0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, ensure that the 'Units_Sold' from daily_data is merged into inventory_fact_df\n",
    "inventory_fact_df = inventory_fact_df.merge(daily_data, on=['Date', 'Product_ID'], how='left')\n",
    "\n",
    "# Initialize an empty list to hold the distributed sales data\n",
    "distributed_sales = []\n",
    "\n",
    "# Iterate over each group of items for the same product and date in the inventory fact DataFrame\n",
    "for (date, product_id), group in inventory_fact_df.groupby(['Date', 'Product_ID']):\n",
    "    items = num_inventory_items[product_id]\n",
    "    total_sales = group['Units_Sold'].iloc[0]  # Total sales for this product on this date\n",
    "    each_item_sales = total_sales // items  # Sales per inventory item\n",
    "    remainder = total_sales % items  # Remainder to be distributed\n",
    "\n",
    "    # Distribute sales across inventory items, adding the remainder to the last item\n",
    "    sales_distribution = [each_item_sales] * items\n",
    "    sales_distribution[-1] += remainder\n",
    "\n",
    "    # Extend the distributed_sales list with the calculated sales distribution\n",
    "    distributed_sales.extend(sales_distribution)\n",
    "\n",
    "# Assign the distributed sales to the 'Daily_Sales' column\n",
    "inventory_fact_df['Daily_Sales'] = distributed_sales\n",
    "\n",
    "# Drop the now unnecessary 'Units_Sold' column\n",
    "inventory_fact_df.drop(columns=['Units_Sold'], inplace=True)\n",
    "\n",
    "# Display the updated inventory fact DataFrame\n",
    "inventory_fact_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-94b2404b2d87>:18: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-1.2261063759441415e+21' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[i, 'Running_Stock'] = df.at[i-1, 'Running_Stock'] + df.at[i, 'Net_Stock_Change']\n",
      "<ipython-input-7-94b2404b2d87>:18: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-2.4296559140710294e+19' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[i, 'Running_Stock'] = df.at[i-1, 'Running_Stock'] + df.at[i, 'Net_Stock_Change']\n",
      "<ipython-input-7-94b2404b2d87>:18: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-3.6572168646601406e+21' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[i, 'Running_Stock'] = df.at[i-1, 'Running_Stock'] + df.at[i, 'Net_Stock_Change']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m            df\u001b[38;5;241m.\u001b[39mat[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning_Stock\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mmin\u001b[39m(df\u001b[38;5;241m.\u001b[39mat[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning_Stock\u001b[39m\u001b[38;5;124m'\u001b[39m], max_stock_per_product), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     21\u001b[0m    \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m---> 23\u001b[0m inventory_fact_df \u001b[38;5;241m=\u001b[39m \u001b[43minventory_fact_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProduct_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalculate_inventory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_stock_per_product\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/tmp/pip_packages/pandas/core/groupby/groupby.py:1824\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, include_groups, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1822\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1823\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1824\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1825\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1826\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, Series)\n\u001b[1;32m   1827\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1828\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1829\u001b[0m         ):\n\u001b[1;32m   1830\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1831\u001b[0m                 message\u001b[38;5;241m=\u001b[39m_apply_groupings_depr\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1832\u001b[0m                     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1835\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1836\u001b[0m             )\n",
      "File \u001b[0;32m/tmp/pip_packages/pandas/core/groupby/groupby.py:1885\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1851\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[1;32m   1852\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1857\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1883\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1885\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_groupwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1886\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1887\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated\n",
      "File \u001b[0;32m/tmp/pip_packages/pandas/core/groupby/ops.py:919\u001b[0m, in \u001b[0;36mBaseGrouper.apply_groupwise\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[1;32m    918\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m--> 919\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    921\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/pip_packages/pandas/core/groupby/groupby.py:1809\u001b[0m, in \u001b[0;36mGroupBy.apply.<locals>.f\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m   1807\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m   1808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(g):\n\u001b[0;32m-> 1809\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m, in \u001b[0;36mcalculate_inventory\u001b[0;34m(df, max_stock_per_product)\u001b[0m\n\u001b[1;32m     10\u001b[0m     df\u001b[38;5;241m.\u001b[39mat[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning_Stock\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m max_stock_per_product\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Calculate restocked units based on sales and max stock constraint\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     restock_needed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDaily_Sales\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, max_stock_per_product \u001b[38;5;241m-\u001b[39m df\u001b[38;5;241m.\u001b[39mat[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning_Stock\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     14\u001b[0m     df\u001b[38;5;241m.\u001b[39mat[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRestocked_Units\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m restock_needed\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Update Net_Stock_Change to reflect restocking\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/pip_packages/pandas/core/indexing.py:2575\u001b[0m, in \u001b[0;36m_AtIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2572\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid call for scalar access (getting)!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2573\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mloc[key]\n\u001b[0;32m-> 2575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/pip_packages/pandas/core/indexing.py:2527\u001b[0m, in \u001b[0;36m_ScalarAccessIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2524\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid call for scalar access (getting)!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2526\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_key(key)\n\u001b[0;32m-> 2527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/pip_packages/pandas/core/frame.py:4214\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   4211\u001b[0m     series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ixs(col, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   4212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[index]\n\u001b[0;32m-> 4214\u001b[0m series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_item_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4215\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_engine\n\u001b[1;32m   4217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[1;32m   4218\u001b[0m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[1;32m   4219\u001b[0m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[1;32m   4220\u001b[0m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/pip_packages/pandas/core/frame.py:4639\u001b[0m, in \u001b[0;36mDataFrame._get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   4634\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4635\u001b[0m     \u001b[38;5;66;03m# All places that call _get_item_cache have unique columns,\u001b[39;00m\n\u001b[1;32m   4636\u001b[0m     \u001b[38;5;66;03m#  pending resolution of GH#33047\u001b[39;00m\n\u001b[1;32m   4638\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(item)\n\u001b[0;32m-> 4639\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ixs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4641\u001b[0m     cache[item] \u001b[38;5;241m=\u001b[39m res\n\u001b[1;32m   4643\u001b[0m     \u001b[38;5;66;03m# for a chain\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/pip_packages/pandas/core/frame.py:4014\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   4011\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_box_col_values(col_mgr, i)\n\u001b[1;32m   4013\u001b[0m \u001b[38;5;66;03m# this is a cached value, mark it so\u001b[39;00m\n\u001b[0;32m-> 4014\u001b[0m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_as_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4015\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/tmp/pip_packages/pandas/core/series.py:1476\u001b[0m, in \u001b[0;36mSeries._set_as_cached\u001b[0;34m(self, item, cacher)\u001b[0m\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_as_cached\u001b[39m(\u001b[38;5;28mself\u001b[39m, item, cacher) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1472\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1473\u001b[0m \u001b[38;5;124;03m    Set the _cacher attribute on the calling object with a weakref to\u001b[39;00m\n\u001b[1;32m   1474\u001b[0m \u001b[38;5;124;03m    cacher.\u001b[39;00m\n\u001b[1;32m   1475\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m   1477\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1478\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cacher \u001b[38;5;241m=\u001b[39m (item, weakref\u001b[38;5;241m.\u001b[39mref(cacher))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def calculate_inventory(df, max_stock_per_product):\n",
    "   df = df.sort_values(by='Date').reset_index(drop=True)  # Ensure chronological order and reset index\n",
    "   # Initialize columns\n",
    "   df['Restocked_Units'] = 0\n",
    "   df['Net_Stock_Change'] = -df['Daily_Sales']  # Assuming sales reduce stock\n",
    "   df['Running_Stock'] = 0\n",
    "   for i in range(len(df)):\n",
    "       if i == 0:  # First entry for the product's inventory items\n",
    "           # Set initial stock levels based on max_stock_per_product\n",
    "           df.at[i, 'Running_Stock'] = max_stock_per_product\n",
    "       else:\n",
    "           # Calculate restocked units based on sales and max stock constraint\n",
    "           restock_needed = min(df.at[i, 'Daily_Sales'], max_stock_per_product - df.at[i-1, 'Running_Stock'])\n",
    "           df.at[i, 'Restocked_Units'] = restock_needed\n",
    "           # Update Net_Stock_Change to reflect restocking\n",
    "           df.at[i, 'Net_Stock_Change'] = restock_needed - df.at[i, 'Daily_Sales']\n",
    "           # Update Running_Stock\n",
    "           df.at[i, 'Running_Stock'] = df.at[i-1, 'Running_Stock'] + df.at[i, 'Net_Stock_Change']\n",
    "           # Ensure Running_Stock is within [0, max_stock_per_product]\n",
    "           df.at[i, 'Running_Stock'] = max(min(df.at[i, 'Running_Stock'], max_stock_per_product), 0)\n",
    "   return df\n",
    "\n",
    "inventory_fact_df = inventory_fact_df.groupby('Product_ID').apply(calculate_inventory, max_stock_per_product=2000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample data\n",
    "print(product_df.head())\n",
    "print(seasonality_df.head())\n",
    "print(inventory_dim_df.head())\n",
    "print(daily_data.head())\n",
    "print(inventory_fact_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Campaign details\n",
    "n_campaigns = 100\n",
    "campaign_types = ['Email Blast', 'Social Media Ad', 'Holiday Sale', 'Limited Time Offer', 'New Product Launch']\n",
    "discount_types = ['Percentage Off', 'Buy One Get One Free', 'Fixed Amount Off']\n",
    "product_categories = ['Dairy', 'Beverages', 'Snacks', 'Cleaning', 'Personal Care', 'Bakery', 'Frozen', 'Produce', 'Meat', 'Cereals']\n",
    "\n",
    "# Campaign DataFrame\n",
    "start_date = pd.to_datetime('2020-01-01')\n",
    "end_date = pd.to_datetime('2024-12-31')\n",
    "date_range = (end_date - start_date).days\n",
    "\n",
    "campaign_df = pd.DataFrame({\n",
    "    'Campaign_ID': range(1, n_campaigns + 1),\n",
    "    'Campaign_Type': np.random.choice(campaign_types, n_campaigns),\n",
    "    'Discount_Type': np.random.choice(discount_types, n_campaigns),\n",
    "    'Targeted_Category': np.random.choice(product_categories, n_campaigns),\n",
    "    'Start_Date': start_date + pd.to_timedelta(np.random.randint(0, date_range - 30, size=n_campaigns), unit='D'),\n",
    "})\n",
    "\n",
    "\n",
    "# Assign End_Date, ensuring it's after Start_Date\n",
    "campaign_df['End_Date'] = campaign_df['Start_Date'] + pd.to_timedelta(np.random.randint(1, 30, size=n_campaigns), unit='D')\n",
    "campaign_df['End_Date'] = campaign_df.apply(lambda row: row['Start_Date'] + pd.DateOffset(days=1) if row['End_Date'] < row['Start_Date'] else row['End_Date'], axis=1)\n",
    "\n",
    "print(campaign_df)\n",
    "campaign_df.to_csv('campaign_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data.to_csv('daily_sales_data.csv')\n",
    "campaign_df.to_csv('campaign_data.csv')\n",
    "inventory_dim_df.to_csv('inventory_dim.csv')\n",
    "inventory_fact_df.to_csv('inventory_fact.csv')\n",
    "product_df.to_csv('product_dim.csv')\n",
    "seasonality_df.to_csv('seasonality_dim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
